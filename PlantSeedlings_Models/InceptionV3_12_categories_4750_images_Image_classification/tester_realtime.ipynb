{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f58fae71d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2\n",
    "import keras\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense, InputLayer, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#from skimage.io import imread\n",
    "#from skimage.transform import resize\n",
    "# Don't use skimage, it sucks (Can't read all iamges). Cv2 is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13629139598515922826\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9849081619739798770\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3264020480\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8966296752706065497\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5628677165803057986\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sess = tensorflow.compat.v1.Session(config=tensorflow.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "config = tensorflow.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tensorflow.compat.v1.Session(config=config) \n",
    "tensorflow.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "INIT_LR = 1e-4\n",
    "BS = 16\n",
    "default_image_size = tuple((299, 299))\n",
    "image_size = 0\n",
    "directory_root = '../../../../Datasets/plant-seedlings-classification/train/' # Can be deleted\n",
    "width=299\n",
    "height=299\n",
    "depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model = load_model('InceptionV3_model1_12_categories_4750_plant_seedlings.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('0bcf29af7.png')\n",
    "image_resized = cv2.resize(image, default_image_size)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = np.load('label_names.npy')\n",
    "label_names = label_names.flatten()\n",
    "label_names = np.ndarray.tolist(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swapped = np.moveaxis(image_resized, 0, 2)  # shape (y_pixels, x_pixels, n_bands)\n",
    "image_resized = np.expand_dims(image_resized, 0)\n",
    "\n",
    "test_predictions = iv3_model.predict(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cleavers'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(test_predictions, axis=1)\n",
    "label_names[int(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing heatmaps of class activation in an image\n",
    "# Cross check one more time with the code from the book\n",
    "# Revise and write in proper way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleavers_output = iv3_model.output[:,np.argmax(test_predictions[0])]\n",
    "last_conv_layer = iv3_model.get_layer('conv2d_93')\n",
    "grads = K.gradients(cleavers_output, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "iterate = K.function([iv3_model.input],[pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([image_resized])\n",
    "\n",
    "for i in range(192):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMWElEQVR4nO3d+49cdRnH8c/H7ZayLdiUIiBtLKDWIFEKDQGbEKVAQAhGYxQSSCSQ+oMSGjQE/EX5BxB+MBjCRRIKBApNlAjSCAQJWuwNubQYIAUql+Ui6ZW2uzz+MKdkaQf37HK+Z6f7vF/JpLOzs+d5dref+Z6ZPXMeR4QATG6fm+gGAJRH0IEECDqQAEEHEiDoQAIEHUigJ4Ju+xzbL9p+yfY1hWvdZnvQ9nMl64yoN9f2Y7Y32H7e9pWF602z/bTtZ6p615WsV9Xss73O9oOla1X1Ntl+1vZ626sL15ppe7ntjdXv8LSCteZX39PeyxbbSxvZeERM6EVSn6SXJR0raaqkZyQdX7De6ZJOkvRcS9/fUZJOqq4fIunfhb8/S5pRXe+XtErSqYW/x6sk3SXpwZZ+ppskzW6p1h2SLq+uT5U0s6W6fZLekvSlJrbXCyv6KZJeiohXImK3pHskfa9UsYh4QtL7pbbfpd6bEbG2ur5V0gZJRxesFxGxrfqwv7oUOyrK9hxJ50m6pVSNiWL7UHUWhlslKSJ2R8QHLZVfLOnliHi1iY31QtCPlvT6iI83q2AQJpLteZIWqLPKlqzTZ3u9pEFJKyOiZL0bJF0t6aOCNfYVkh6xvcb2koJ1jpX0jqTbq6cmt9ieXrDeSBdKurupjfVC0N3ltkl3XK7tGZLul7Q0IraUrBURwxFxoqQ5kk6xfUKJOrbPlzQYEWtKbP//WBQRJ0k6V9LPbJ9eqM4UdZ7m3RQRCyRtl1T0NSRJsj1V0gWS7mtqm70Q9M2S5o74eI6kNyaolyJs96sT8mUR8UBbdavdzMclnVOoxCJJF9jepM5TrjNs31mo1sci4o3q30FJK9R5+lfCZkmbR+wRLVcn+KWdK2ltRLzd1AZ7Iej/lPQV28dUj2QXSvrjBPfUGNtW5znehoi4voV6h9ueWV0/WNKZkjaWqBUR10bEnIiYp87v7dGIuLhErb1sT7d9yN7rks6WVOQvKBHxlqTXbc+vblos6YUStfZxkRrcbZc6uyYTKiKGbP9c0l/UeaXxtoh4vlQ923dL+rak2bY3S/p1RNxaqp46q94lkp6tnjdL0q8i4s+F6h0l6Q7bfeo8kN8bEa382aslR0ha0Xn81BRJd0XEwwXrXSFpWbUIvSLp0oK1ZHtA0lmSftrodquX8gFMYr2w6w6gMIIOJEDQgQQIOpAAQQcS6KmgFz6cccJqUY96E12vp4Iuqc0fZqu/OOpRbyLr9VrQARRQ5ICZvoHp0T9z1pi/bnjHdvUNjP3NQR4e85doeOd29R08vjci9Q9uH/PX7NEu9eugcdUbjwOq3sC0sdcb2qH+KQPjKudx/JffPbRDU8dZL3Z+OOavGe/P80Nt1+7Ytd8bxYocAts/c5bmXX5ViU13r7e1tVKSpCNvfKrdgpOcv/b1duu1fDToR+vbODy+Y1X8tevt7LoDCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUigVtDbHJkEoHmjBr06yeDv1DkF7fGSLrJ9fOnGADSnzore6sgkAM2rE/Q0I5OAyapO0GuNTLK9xPZq26uHd4z93V0AyqkT9FojkyLi5ohYGBELx/NWUwDl1An6pB6ZBGQw6vvR2x6ZBKB5tU48Uc0JKzUrDEBhHBkHJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBIpNaPCz1byux5e4OfW0cM5nQM2Jduwda7j7z5FbrTfvqca3V8qYnu97Oig4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEE6oxkus32oO3n2mgIQPPqrOh/kHRO4T4AFDRq0CPiCUnvt9ALgEJ4jg4k0FjQPzF7bSez14Be0ljQPzF77WBmrwG9hF13IIE6f167W9LfJc23vdn2ZeXbAtCkOkMWL2qjEQDlsOsOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBIrPX+ge368gbniqxaUxCr/3mW63WO/nsF1qtt+5Px7dWa/dt3SPNig4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEE6pwccq7tx2xvsP287SvbaAxAc+oc6z4k6RcRsdb2IZLW2F4ZEe0eMAxg3OrMXnszItZW17dK2iDp6NKNAWjOmJ6j254naYGkVSWaAVBG7bep2p4h6X5JSyNiS5fPL5G0RJKmaaCxBgF8drVWdNv96oR8WUQ80O0+I2ev9eugJnsE8BnVedXdkm6VtCEiri/fEoCm1VnRF0m6RNIZttdXl+8W7gtAg+rMXntSklvoBUAhHBkHJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBIrPXcGDb9qNTW633yx93fftEMZd9/q1W6x1z3Jdbq/XRQdH1dlZ0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJFDnLLDTbD9t+5lq9tp1bTQGoDl1jnXfJemMiNhWnd/9SdsPRcQ/CvcGoCF1zgIbkrZVH/ZXl+5HzgPoSXUntfTZXi9pUNLKiGD2GnAAqRX0iBiOiBMlzZF0iu0T9r2P7SW2V9tevUe7mu4TwGcwplfdI+IDSY9LOqfL55i9BvSoOq+6H257ZnX9YElnStpYujEAzanzqvtRku6w3afOA8O9EfFg2bYANKnOq+7/krSghV4AFMKRcUACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEmD2Gvaz8+L/TnQLRf3+g6NbrTf17f7WannIXW9nRQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACtYNeDXFYZ5sTQwIHmLGs6FdK2lCqEQDl1B3JNEfSeZJuKdsOgBLqrug3SLpa0kcFewFQSJ1JLedLGoyINaPcj9lrQI+qs6IvknSB7U2S7pF0hu07970Ts9eA3jVq0CPi2oiYExHzJF0o6dGIuLh4ZwAaw9/RgQTGdCqpiHhcnbHJAA4grOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxJg9hr299CsVsv99qkftFpvx9zhVuvNeK/7PLQSPNT9dlZ0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJFDrENjqVM9bJQ1LGoqIhSWbAtCssRzr/p2IeLdYJwCKYdcdSKBu0EPSI7bX2F5SsiEAzau7674oIt6w/QVJK21vjIgnRt6hegBYIknTNNBwmwA+i1orekS8Uf07KGmFpFO63IfZa0CPqjNNdbrtQ/Zel3S2pOdKNwagOXV23Y+QtML23vvfFREPF+0KQKNGDXpEvCLpmy30AqAQ/rwGJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABZq9hP0cue77Vep41s9V6L186p9V6e2a0Vys+ZelmRQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACtYJue6bt5bY32t5g+7TSjQFoTt1j3W+U9HBE/ND2VIkJDcCBZNSg2z5U0umSfiJJEbFb0u6ybQFoUp1d92MlvSPpdtvrbN9SDXL4BNtLbK+2vXqPdjXeKIDxqxP0KZJOknRTRCyQtF3SNfveiZFMQO+qE/TNkjZHxKrq4+XqBB/AAWLUoEfEW5Jetz2/ummxpBeKdgWgUXVfdb9C0rLqFfdXJF1ariUATasV9IhYL2lh4V4AFMKRcUACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEigye21o9nS99/32zk2xdV5rpSbEF/+2p9V6O2e3O5Lvw8PaXW++sfjFVuu9MHhka7U8MNz1dlZ0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQggVGDbnu+7fUjLltsL22jOQDNGPVYx4h4UdKJkmS7T9J/JK0o3BeABo11132xpJcj4tUSzQAoY6xBv1DS3SUaAVBO7aBX53S/QNJ9n/L5j2evDX24van+ADRgLCv6uZLWRsTb3T45cvbalGn7zWAEMIHGEvSLxG47cECqFXTbA5LOkvRA2XYAlFB3JNMOSYcV7gVAIRwZByRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJOCIaH6j9juSxvOe9dmS3m24nV6oRT3qtVXvSxFx+L43Fgn6eNleHRELJ1st6lFvouux6w4kQNCBBHot6DdP0lrUo96E1uup5+gAyui1FR1AAQQdSICgAwkQdCABgg4k8D8qK7dCbZ8q8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.savefig('heat_map_cleavers.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('0bcf29af7.png')\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('heat_map_superimposed_cleavers.png', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
